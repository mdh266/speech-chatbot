{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building & Deploying A Serverless Multimodal ChatBot: Part 2\n",
    "--------------------------------------------------\n",
    "\n",
    "__[1. Introduction](#first-bullet)__\n",
    "\n",
    "__[2. Docker & DockerHub](#second-bullet)__\n",
    "\n",
    "__[3. GitHub Actions For CI/CD](#third-bullet)__\n",
    "\n",
    "__[4. Deploying On Google Cloud Run](#fourth-bullet)__\n",
    "\n",
    "__[5. Conclusions](#fifth-bullet)__\n",
    "\n",
    "\n",
    "### Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "----------------\n",
    "In my last post I went over how to create a create speech based chatbot app with a [Large Language Model (LLM)](https://en.wikipedia.org/wiki/Large_language_model) using [LangChain](https://www.langchain.com/), [Llama 3](https://ai.meta.com/blog/meta-llama-3/), [Google Cloud API]() and [Streamlit](https://streamlit.io/).\n",
    "\n",
    " In this post I'll cover how to deploy this app using [Docker](https://www.docker.com/) for containerization. Containerizing the app will allow us to run it both locally and on the cloud. Then I'll cover [GitHub Actions](https://github.com/features/actions) for automatically building the image and pushing it to [Docker Hub](https://hub.docker.com/) where it can be pulled and run on [Google Cloud Run](https://cloud.google.com/run) to create a serverless application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker & DockerHub <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docker](https://www.docker.com/) is the industry standard when it comes to containarizing applications. Containerization has made deploying applications and maintaining them across different environments much easier! Once a container is running on one computer it runs on all computers with Docker installed on it.\n",
    "\n",
    "The three things you should know about Docker are: [images, containers](https://aws.amazon.com/compare/the-difference-between-docker-images-and-containers/) and [Dockerfiles](https://docs.docker.com/get-started/docker-concepts/building-images/writing-a-dockerfile/).\n",
    "\n",
    "A Docker image is a blue-print for a Docker container. A container is the instantiation of that image. This is similar to the way an object is an instantiation of a class in object oriented programing. The definition of an image is given by the Dockerfile. The Dockerfile for this project is pretty simple:\n",
    "\n",
    "    FROM python:3.11-slim\n",
    "\n",
    "    RUN mkdir /app\n",
    "    RUN mkdir /app/src\n",
    "    WORKDIR /app\n",
    "\n",
    "    COPY src /app/src\n",
    "    COPY pyproject.toml /app\n",
    "    COPY entrypoint.sh /app\n",
    "    RUN chmod +x /app/entrypoint.sh\n",
    "    RUN pip install . --no-cache \n",
    "\n",
    "    ENTRYPOINT [\"/app/entrypoint.sh\"]\n",
    "\n",
    "The two things that I will point out that are a little different is the use of `--no-cache` for pip installing our Python dependencies. By default pip stores the download packages in a cached directory so that subsequent installations of the same package will be faster.  However, since we dont need re-install anything in the container and the packages can take up signficant space (causing the images to bloat) I avoid the caching. This made my image to be 618MB while with caching packages the image was 734MB. 100MB may not seem like much, but it's almost 20% larger with caching and prior images of mine used tons of packages with caching and are GBs in size.\n",
    "\n",
    "The second point I'll call out is the use of the [entrypoint.sh](https://github.com/mdh266/thirdapp/blob/main/entrypoint.sh) script. For some reason it was not possible to run Streamlit on Google Cloud Run using the `streamlit run ...` command directly in the `ENTRYPOINT`, but invoking a Bash script  with that command in it did work and that's the reason for it!\n",
    "\n",
    "The Docker image can be built from the Dockerfile using the command,\n",
    "\n",
    "    docker image build -t <image_name> .\n",
    "\n",
    "The container can be run using the command,\n",
    "\n",
    "    docker run -ip 8080:8080 -e GROQ_API_KEY=<your-groq-api> -e GOOGLE_API_KEY=<your-google-api>\n",
    "\n",
    "Notice I had to use `-ip 8080:8080` to perform [port-forwarding](https://en.wikipedia.org/wiki/Port_forwarding) from the container to my machine. I used port 8080 instead of Streamlit's default port of 8051 since Google Cloud Run uses port 8080 and its easy enough to switch ports in Docker. I also pass the API keys in as environment variables to the container using the `-e` syntax. \n",
    "\n",
    "**NEVER load your `.env` file in your image or set your API keys in the image. If you, then anyone can get them when they get access to the image!\n",
    "\n",
    "It is a little bit annoying to have to pass this environment variables all the time, especially as you use more and more API keys, so for local development I used [Docker Compose](https://docs.docker.com/compose/) and the follwing [docker-compose.yml](https://github.com/mdh266/thirdapp/blob/main/docker-compose.yml) file,\n",
    "\n",
    "    services:\n",
    "    app:\n",
    "        build: .\n",
    "        env_file: \".env\"\n",
    "        ports:\n",
    "        - \"8080:8080\"\n",
    "\n",
    "Noice the `app` specifies building the image and the `env_file` variable specifies my \".env\" with my API keys. This is **okay** since Docker Compose will inject the environment variables into the container and not the image! You can start up the container with the command,\n",
    "\n",
    "    docker compose up\n",
    "\n",
    "And then the site should be running on https://localhost:8080.\n",
    "\n",
    "The last part to this section is a discussion of [DockerHUB](https://hub.docker.com/). DockerHub is a repository used to host Docker images that can used to pull images from and run them on different platforms. I used DockerHub to host the image so that I could pull it and run it from Google Cloud Run. The command to do so is,\n",
    "\n",
    "    docker push mdh266/thirdapp:cloudrun\n",
    "\n",
    "where `mdh266` is my DockerHub account name, `thirdapp` is the name of the image and `cloudrun` is the tag for the version. One problem that I had was I used a M1 based Apple computer to build the image and had trouble running it on a Linux machine on Google. This is a [known problem](https://pythonspeed.com/articles/docker-build-problems-mac/) and I used this as an opportunity to build the image on a Linux machine using [GitHub Actions](https://github.com/features/actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Actions For CI/CD <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GitHub Actions](https://github.com/features/actions) is an easy way to integrate [CI/CD](https://en.wikipedia.org/wiki/CI/CD) natively with GitHub. I'll create a GitHub Action to build and push the Docker Image for this project to DockerHub I'll create a YAML file called [docker-build.yaml](https://github.com/mdh266/speech-chatbot/blob/main/.github/workflows/docker-build.yaml) that has to be under the following (hidden) folder structure:\n",
    "\n",
    "    speech-chatapp/\n",
    "        .github/workflows/docker-build.yaml\n",
    "\n",
    "\n",
    "This action will run on the any push to the main branch. On action kicks off a job that is defines as,\n",
    "\n",
    "    jobs:\n",
    "        docker:\n",
    "            runs-on: ubuntu-latest\n",
    "            steps:\n",
    "            - name: checkout\n",
    "                uses: actions/checkout@v3\n",
    "            \n",
    "            - name: Login to Docker Hub\n",
    "                uses: docker/login-action@v3\n",
    "                with:\n",
    "                username: ${{ secrets.DOCKERHUB_USERNAME }}\n",
    "                password: ${{ secrets.DOCKERHUB_TOKEN }}\n",
    "\n",
    "            - name: Build & Push Docker\n",
    "                run: | \n",
    "                docker build -t mdh266/thirdapp:cloudrun .\n",
    "                docker push mdh266/thirdapp:cloudrun \n",
    "\n",
    " The `docker` job runs on an ubuntu based machine and run steps that checkout the code, signs into to Docker Hub, builds and pushes the images. Notice that I have to use variables called `${{ secrets.DOCKERHUB_USERNAME }}` and `${{ secrets.DOCKERHUB_TOKEN }}` which hold my Docker Hub user name and Docker Hub API. In order to set these I have to add the secrets to the GitHub repo. I click on \"Settings\" for the repo then on the bottom left panel I click on \"Secrets and Variables\" and then click on \"Actions\" as shown below,\n",
    "\n",
    " ![images/3_github_secrets.png](images/3_github_secrets.png)\n",
    "\n",
    " I can click on the green \"New repository secret\" and then add the `DOCKERHUB_USERNAME` with the value shown below,\n",
    "\n",
    "![images/2_addghsecret.png](images/2_addghsecret.png)\n",
    "\n",
    "Now I am all set up so that any time I push to the main branch it will rebuild the Docker image and push it to Docker Hub. The last step is to deploy the container on Google Cloud Run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying On Google Cloud Run <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying on app on [Google Cloud Run](https://cloud.google.com/run?hl=en) is relatively straight forward. You can create an app by clicking \"DEPLOY CONTAINER\" shown below\n",
    "\n",
    "![images/0_deploy.jpg](images/0_deploy.jpg)\n",
    "\n",
    "Then select \"Service\" then fill out the form as shown below:\n",
    "\n",
    "![images/5_CreateApp.png](images/5_CreateApp.png)\n",
    "\n",
    "Notice that \"Container image URL\" matches the image name I pushed that I pushed to Docker Hub. Then scrolling down we can see the settings I made for the number of instances scale down to zero (to reduce cost) and then to allow all anyone to access the app I set \"Ingress Control\" to \"All\" and \"Authentication\" to \"Allow unathenticated invocations\", \n",
    "\n",
    "![images/6_AllTraffic.png](images/6_AllTraffic.png)\n",
    "\n",
    "Lastly click on the \"Container(s), Volume, Networks, Security\" then we can set the API keys as Environment Variables as shown below,\n",
    "\n",
    "![images/8_API_KEYS.png](images/8_API_KEYS.png)\n",
    "\n",
    "Then we can \"Create\" at the very bottom and we are done!\n",
    "\n",
    "Lastly, if I wanted to create an actual website name and use [Domain NameSpace (DNS) Mapping](https://cloud.google.com/appengine/docs/legacy/standard/python/mapping-custom-domains) so that I can have an actual web address thats more usable. In order to do so I followed the steps laid out in [this youtube video](https://www.youtube.com/watch?v=lDtvpUYAFzA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post I went over a lot, but the steps are pretty straight forward. I covered how to build Docker images, set up GitHub actions to automatically build and push the Docker image to DockerHub and then pull that image and run it as a container on Google Cloud Run. \n",
    "\n",
    "I hope you enjoyed it!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
