{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building & Deploying A Serverless Multimodal ChatBot: Part 2\n",
    "--------------------------------------------------\n",
    "\n",
    "__[1. Introduction](#first-bullet)__\n",
    "\n",
    "__[2. Docker & DockerHub](#second-bullet)__\n",
    "\n",
    "__[3. GitHub Actions For CI/CD](#third-bullet)__\n",
    "\n",
    "__[4. Deploying On Google Cloud Run](#fourth-bullet)__\n",
    "\n",
    "__[5. Conclusions](#fifth-bullet)__\n",
    "\n",
    "\n",
    "### Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "----------------\n",
    "In my last post I went over how to create a create speech based chatbot app with a [Large Language Model (LLM)](https://en.wikipedia.org/wiki/Large_language_model) using [LangChain](https://www.langchain.com/), [Llama 3](https://ai.meta.com/blog/meta-llama-3/), [Google Cloud API]() and [Streamlit](https://streamlit.io/).\n",
    "\n",
    " In this post I'll cover how to deploy this app using [Docker](https://www.docker.com/) for containerization. Containerizing the app will allow us to run it both locally and on the cloud. Then I'll cover [GitHub Actions](https://github.com/features/actions) for automatically building the image and pushing it to [Docker Hub](https://hub.docker.com/) where it can be pulled and run on [Google Cloud Run](https://cloud.google.com/run) to create a serverless application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker & DockerHub <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docker](https://www.docker.com/) is the industry standard when it comes to containarizing applications. Containerization has made deploying applications and maintaining them across different environments much easier! Once a container is running on one computer it runs on all computers with Docker installed on it.\n",
    "\n",
    "The three things you should know about Docker are: [images, containers](https://aws.amazon.com/compare/the-difference-between-docker-images-and-containers/) and [Dockerfiles](https://docs.docker.com/get-started/docker-concepts/building-images/writing-a-dockerfile/).\n",
    "\n",
    "A Docker image is a blue-print for a Docker container. A container is the instantiation of that image. This is similar to the way an object is an instantiation of a class in object oriented programing. The definition of an image is given by the Dockerfile. The Dockerfile for this project is pretty simple:\n",
    "\n",
    "    FROM python:3.11-slim\n",
    "\n",
    "    RUN mkdir /app\n",
    "    RUN mkdir /app/src\n",
    "    WORKDIR /app\n",
    "\n",
    "    COPY src /app/src\n",
    "    COPY pyproject.toml /app\n",
    "    COPY entrypoint.sh /app\n",
    "    RUN chmod +x /app/entrypoint.sh\n",
    "    RUN pip install . --no-cache \n",
    "\n",
    "    ENTRYPOINT [\"/app/entrypoint.sh\"]\n",
    "\n",
    "The two things that I will point out that are a little different is the use of `--no-cache` for pip installing our Python dependencies. By default pip stores the download packages in a cached directory so that subsequent installations of the same package will be faster.  However, since we dont need re-install anything in the container and the packages can take up signficant space (causing the images to bloat) I avoid the caching. This made my image to be 618MB while with caching packages the image was 734MB. 100MB may not seem like much, but it's almost 20% larger with caching and prior images of mine used tons of packages with caching and are GBs in size.\n",
    "\n",
    "The second point I'll call out is the use of the [entrypoint.sh](https://github.com/mdh266/thirdapp/blob/main/entrypoint.sh) script. For some reason it was not possible to run Streamlit on Google Cloud Run using the `streamlit run ...` command directly in the `ENTRYPOINT`, but invoking a Bash script  with that command in it did work and that's the reason for it!\n",
    "\n",
    "The Docker image can be built from the Dockerfile using the command,\n",
    "\n",
    "    docker image build -t <image_name> .\n",
    "\n",
    "The container can be run using the command,\n",
    "\n",
    "    docker run -ip 8080:8080 -e GROQ_API_KEY=<your-groq-api> -e GOOGLE_API_KEY=<your-google-api>\n",
    "\n",
    "Notice I had to use `-ip 8080:8080` to perform [port-forwarding](https://en.wikipedia.org/wiki/Port_forwarding) from the container to my machine. I used port 8080 instead of Streamlit's default port of 8051 since Google Cloud Run uses port 8080 and its easy enough to switch ports in Docker. I also pass the API keys in as environment variables to the container using the `-e` syntax. \n",
    "\n",
    "**NEVER load your `.env` file in your image or set your API keys in the image. If you, then anyone can get them when they get access to the image!\n",
    "\n",
    "It is a little bit annoying to have to pass this environment variables all the time, especially as you use more and more API keys, so for local development I used [Docker Compose](https://docs.docker.com/compose/) and the follwing [docker-compose.yml](https://github.com/mdh266/thirdapp/blob/main/docker-compose.yml) file,\n",
    "\n",
    "    services:\n",
    "    app:\n",
    "        build: .\n",
    "        env_file: \".env\"\n",
    "        ports:\n",
    "        - \"8080:8080\"\n",
    "\n",
    "Noice the `app` specifies building the image and the `env_file` variable specifies my \".env\" with my API keys. This is **okay** since Docker Compose will inject the environment variables into the container and not the image! You can start up the container with the command,\n",
    "\n",
    "    docker compose up\n",
    "\n",
    "And then the site should be running on https://localhost:8080.\n",
    "\n",
    "The last part to this section is a discussion of [DockerHUB](https://hub.docker.com/). DockerHub is a repository used to host Docker images that can used to pull images from and run them on different platforms. I used DockerHub to host the image so that I could pull it and run it from Google Cloud Run. The command to do so is,\n",
    "\n",
    "    docker push mdh266/thirdapp:cloudrun\n",
    "\n",
    "where `mdh266` is my DockerHub account name, `thirdapp` is the name of the image and `cloudrun` is the tag for the version. One problem that I had was I used a M1 based Apple computer to build the image and had trouble running it on a Linux machine on Google. This is a [known problem](https://pythonspeed.com/articles/docker-build-problems-mac/) and I used this as an opportunity to build the image on a Linux machine using [GitHub Actions](https://github.com/features/actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Actions For CI/CD <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GitHub Actions](https://github.com/features/actions) is an easy way to integrate [CI/CD](https://en.wikipedia.org/wiki/CI/CD) natively with GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying On Google Cloud Run <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
